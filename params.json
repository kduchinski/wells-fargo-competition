{"name":"Wells Fargo 2015 Campus Analytics Challenge","tagline":"","body":"# Introduction\r\ndescription of the goals of this project and what we did to accomplish them \r\nthank wells fargo and mindsumo  \r\nflow diagram\r\n\r\n# What financial topics do consumers discuss on social media and what caused the consumers to post about this topic?\r\n##Approach\r\ndescribe approach to this question in more detail  \r\n```R\r\n#To isolate posts mentioning Bank A  \r\nbankA.idx = which(sapply(df$FullText,function(x) grepl(\"BankA\",x)))\r\n``` \r\n##Bank A\r\n![Bank A Wordcloud](http://i.imgur.com/zcWUqB5.png?1) | ![Bank A Term-Frequency Plot](http://i.imgur.com/XkZbFQ2.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------\r\nidentify 3 key terms\r\nsentiment analysis of 3 key terms  \r\nwordcloud of \"good\"  \r\nanalysis of results\r\n##Bank B\r\n![Bank B Wordcloud](http://i.imgur.com/Cxxvipl.png?1) | ![Bank B Term-Frequency Plot](http://i.imgur.com/wzbM4NO.png?1)\r\n----------------------------------------------------- | --------------------------------------------------------------- \r\n##Bank C\r\n![Bank C Wordcloud](http://i.imgur.com/zXFuQbG.png?2) | ![Bank C Term-Frequency Plot](http://i.imgur.com/6yS4Kr4.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------  \r\n##Bank D\r\n![Bank D Wordcloud](http://i.imgur.com/LHnTSiS.png?1) | ![Bank D Term-Frequency Plot](http://i.imgur.com/v3Qmsyk.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------  \r\n##Methods\r\n```R\r\n#To generate a wordcloud from a term-document matrix \"tdm\"\r\nlibrary(wordcloud)\r\nm <- as.matrix(tdm)\r\nword.freq <- sort(rowSums(m), decreasing = T)\r\npal <- brewer.pal(9, \"BuGn\")\r\npal <- pal[-(1:4)]\r\nlibrary(wordcloud)\r\nwordcloud(words = names(word.freq), freq = word.freq, min.freq=2500, random.order=F, random.color=F, colors = pal)\r\n```\r\n```R\r\n#To generate a term-frequency plot from a term-document matrix \"tdm\"\r\nterm.freq <- rowSums(as.matrix(tdm))\r\nterm.freq <- subset(term.freq, term.freq >= 5000) #Selects terms that occur more than 5000 times\r\ndf <- data.frame(term = names(term.freq), freq = term.freq)\r\nlibrary(ggplot2)\r\nggplot(df, aes(x=term, y=freq)) + geom_bar(stat = \"identity\") + xlab(\"Terms\") + ylab(\"Count\") + coord_flip()\r\n```\r\nOur sentiment analysis involves the custom function score.sentiment, which can be found at the bottom of this webpage.\r\n```R\r\n#To generate a sentiment analysis box plot from a dataframe \"df\" containing consumer comments under the column \"FullText\"\r\nscores = score.sentiment(df$FullText, pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 2)\r\nscores$very.neg = as.numeric(scores$score <= -2)\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\n  geom_boxplot(aes(fill=mediatype)) +\r\n  scale_fill_manual(values=cols) +\r\n  geom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\n  labs(title = \"Media Type's Sentiment Scores\") + \r\n  xlab('Media Type') + ylab('Sentiment Score')\r\n```\r\n# Are the topics and “substance” consistent across the industry or are they isolated to individual banks?\r\n##Approach\r\ndescribe approach to this question in more detail\r\n##Industry\r\nwordcloud, tf plot, sa\r\ndiscuss common terms\r\ndiscuss sentiment scores for each bank vs. industry\r\n##Bank A\r\n##Bank B  \r\n##Bank C  \r\n##Bank D  \r\n##Methods\r\nsa (scores)\r\n\r\n#Custom Functions\r\n###stemCompletion_mod\r\n```R\r\nstemCompletion_mod <- function(x,dict=dictCorpus) \r\n{\r\n  paste(stemCompletion(unlist(strsplit(as.character(x),\" \")),dict, type=\"longest\"),sep=\" \",collapse=\" \")\r\n}\r\n```\r\n###score.sentiment\r\n```R\r\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n{\r\n  require(plyr)\r\n  require(stringr)\r\n\r\n  scores = laply(sentences, function(sentence, pos.words, neg.words)\r\n  {\r\n    word.list = str_split(sentence, '\\\\s+') #splits sentences for analysis into individual words\r\n    words = unlist(word.list)\r\n\r\n    # compare our words to the dictionaries of positive & negative terms\r\n    pos.matches = match(words, pos.words)\r\n    neg.matches = match(words, neg.words)\r\n    pos.matches = !is.na(pos.matches)\r\n    neg.matches = !is.na(neg.matches)\r\n    \r\n    score = sum(pos.matches) - sum(neg.matches)\r\n    return(score)\r\n  }\r\n  \r\n  scores.df = data.frame(score=scores, text=sentences)\r\n  return(scores.df)\r\n}\r\n```\r\n## Authors and Contributors\r\ndescription of collaboration\r\n\\@nashkenziem\r\n\\@emilyberich\r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out our [documentation](https://help.github.com/pages) or [contact support](https://github.com/contact) and we’ll help you sort it out.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}