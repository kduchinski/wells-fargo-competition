{"name":"Wells Fargo 2015 Campus Analytics Challenge","tagline":"","body":"# Introduction\r\ndescription of the goals of this project and what we did to accomplish them \r\nthank wells fargo and mindsumo  \r\nflow diagram\r\n\r\n# What financial topics do consumers discuss on social media and what caused the consumers to post about this topic?\r\n##Approach\r\nWord clouds, clusters of related words, allow us to visually represent words that occur frequently. Thus, they can reveal what consumers talk about on social media. We split the data into collections of posts related to each bank respectively and removed common words like prepositions, URLs, and the name of the bank in question. We then determined the most frequently used words and spell-checked them before making a word cloud. Term-frequency plots, bar graphs of how often each word appears in the Facebook and Twitter posts, represent the same information but in a quantitative manner. From these graphs we derived popular banking topics on\r\nsocial media. But are users praising these aspects of banking or criticizing them? Sentiment analysis determines if a given word is positive or negative. We treated the social media posts about each banking topic as a list of words in order to see if the social conversation around different aspects of banking is positive or negative overall.\r\n```R\r\n#To isolate posts mentioning BankA \r\nbankA.idx = which(sapply(df$FullText,function(x) grepl(\"BankA\",x)))\r\n#To isolate posts mentioning BankA and service\r\nservice.idx = which(sapply(df$FullText[bankA.idx],function(x) grep1(\"service\",x)))\r\n``` \r\n##Bank A\r\n![Bank A Wordcloud](http://i.imgur.com/zcWUqB5.png?1) | ![Bank A Term-Frequency Plot](http://i.imgur.com/XkZbFQ2.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------\r\nThese graphs depict the most frequently-used words in tweets and Facebook posts about BankA. All of the words in the word cloud appear at least 700 times, and all of the words in the term-frequency plot appear at least 1000 times. \r\n\r\nConsumers frequently compare BankA to BankB, so BankB may be BankA's biggest competitor. They also compare it\r\nto BankD to a lesser extent. The words \"great\" and \"good\" appear much more frequently than \"hate\" or profanities, which suggests that there may be more positive posts than negative posts concerning BankA. Some interesting topics that appear in the word cloud are **service**, **deposit**, and **card**.  \r\n\r\nsentiment analysis of 3 key terms  \r\nwordcloud of \"good\" + \"great\" and \"fuck\" + \"hate\"  \r\nanalysis of results\r\n##Bank B\r\n![Bank B Wordcloud](http://i.imgur.com/Cxxvipl.png?1) | ![Bank B Term-Frequency Plot](http://i.imgur.com/wzbM4NO.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------   \r\nThese graphs depict the most frequently-used words in tweets and Facebook posts about BankB. All of the words in the word cloud appear at least 700 times, and all of the words in the term-frequency plot appear at least 1000 times. \r\nset\r\nSocial media users often compare BankB to each of the other three banks, though BankC is mentioned only about half as often as Banks A and D. Unlike for BankA, for BankB profanity is present in the posts about as often as the words \"good\" and \"great,\" which may indicate a less positive reception of BankB. **Check**, **card**, and **service** are a few key terms from BankB's word cloud.  \r\n\r\n##Bank C\r\n![Bank C Wordcloud](http://i.imgur.com/zXFuQbG.png?2) | ![Bank C Term-Frequency Plot](http://i.imgur.com/6yS4Kr4.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------  \r\nThese graphs depict the most frequently-used words in tweets and Facebook posts about BankB. All of the words in the word cloud appear at least 400 times, and all of the words in the term-frequency plot appear at least 1000 times. The minimum frequency for BankC's word cloud was lowered because consumers mention each of the other three banks about twice as much as BankC.  \r\n\r\nFar fewer posts in the dataset mention BankC than any of the other three banks. BankC may have less account holders than the other banks, or BankC may be more popular among clients over the age of 50, fewer of whom use social networking websites ([Pew Research Center](http://www.pewinternet.org/fact-sheets/social-networking-fact-sheet/). The financial terms we will analysis for sentiment for BankC are **card**, **credit**, and **rate**.\r\n##Bank D\r\n![Bank D Wordcloud](http://i.imgur.com/LHnTSiS.png?1) | ![Bank D Term-Frequency Plot](http://i.imgur.com/v3Qmsyk.png?1)\r\n----------------------------------------------------- | ---------------------------------------------------------------  \r\nThese graphs depict the most frequently-used words in tweets and Facebook posts about BankD. All of the words in the word cloud appear at least 700 times, and all of the words in the term-frequency plot appear at least 1000 times. \r\n\r\nFor each bank, the names of at least two other banks appear in the word cloud. However, the term-frequency plots show that posts about BankD do not mention other banks as much as posts about Banks A, B, and C. In other words, posts related to BankD are primarily about BankD rather than about comparing BankD to another bank. Interestingly, posts about BankD do not use as many adjectives as Banks A and B, either, and the word \"news\" appears in the word cloud. It is possible that many of the social media posts about BankD are made by online news accounts rather than consumers. A few intriguing terms from the word cloud are: **program**, **manage**, and **service**. \r\n```R\r\n#To generate a word cloud from a term-document matrix \"tdm\"\r\nlibrary(wordcloud)\r\nm <- as.matrix(tdm)\r\nword.freq <- sort(rowSums(m), decreasing = T)\r\npal <- brewer.pal(9, \"BuGn\")\r\npal <- pal[-(1:4)]\r\nlibrary(wordcloud)\r\nwordcloud(words = names(word.freq), freq = word.freq, min.freq=2500, random.order=F, random.color=F, colors = pal)\r\n```\r\n```R\r\n#To generate a term-frequency plot from a term-document matrix \"tdm\"\r\nterm.freq <- rowSums(as.matrix(tdm))\r\nterm.freq <- subset(term.freq, term.freq >= 5000) #Selects terms that occur more than 5000 times\r\ndf <- data.frame(term = names(term.freq), freq = term.freq)\r\nlibrary(ggplot2)\r\nggplot(df, aes(x=term, y=freq)) + geom_bar(stat = \"identity\") + xlab(\"Terms\") + ylab(\"Count\") + coord_flip()\r\n```\r\nOur sentiment analysis involves the custom function score.sentiment, which can be found at the bottom of this webpage.\r\n```R\r\n#To generate a sentiment analysis box plot from a dataframe \"df\" containing consumer comments under the column \"FullText\"\r\nscores = score.sentiment(df$FullText, pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 2)\r\nscores$very.neg = as.numeric(scores$score <= -2)\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\n  geom_boxplot(aes(fill=mediatype)) +\r\n  scale_fill_manual(values=cols) +\r\n  geom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\n  labs(title = \"Media Type's Sentiment Scores\") + \r\n  xlab('Media Type') + ylab('Sentiment Score')\r\n```\r\n# Are the topics and “substance” consistent across the industry or are they isolated to individual banks?\r\n##Approach\r\ndescribe approach to this question in more detail\r\n##Industry\r\nwordcloud, tf plot, sa\r\ndiscuss common terms\r\ndiscuss sentiment scores for each bank vs. industry\r\n##Bank A\r\n##Bank B  \r\n##Bank C  \r\n##Bank D  \r\n##Methods\r\nsa (scores)\r\n\r\n#Custom Functions\r\n###stemCompletion_mod\r\n```R\r\nstemCompletion_mod <- function(x,dict=dictCorpus) \r\n{\r\n  paste(stemCompletion(unlist(strsplit(as.character(x),\" \")),dict, type=\"longest\"),sep=\" \",collapse=\" \")\r\n}\r\n```\r\n###score.sentiment\r\n```R\r\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n{\r\n  require(plyr)\r\n  require(stringr)\r\n\r\n  scores = laply(sentences, function(sentence, pos.words, neg.words)\r\n  {\r\n    word.list = str_split(sentence, '\\\\s+') #splits sentences for analysis into individual words\r\n    words = unlist(word.list)\r\n\r\n    # compare our words to the dictionaries of positive & negative terms\r\n    pos.matches = match(words, pos.words)\r\n    neg.matches = match(words, neg.words)\r\n    pos.matches = !is.na(pos.matches)\r\n    neg.matches = !is.na(neg.matches)\r\n    \r\n    score = sum(pos.matches) - sum(neg.matches)\r\n    return(score)\r\n  }\r\n  \r\n  scores.df = data.frame(score=scores, text=sentences)\r\n  return(scores.df)\r\n}\r\n```\r\n## Authors and Contributors\r\ndescription of collaboration\r\n\\@nashkenziem\r\n\\@emilyberich\r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out our [documentation](https://help.github.com/pages) or [contact support](https://github.com/contact) and we’ll help you sort it out.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}